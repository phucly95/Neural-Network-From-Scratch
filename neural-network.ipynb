{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e1d5f3-cf70-4ef6-a124-d45b5ccdc5a6",
   "metadata": {},
   "source": [
    "# Preprocess Data\n",
    "Load data from file\n",
    "Convert image data to [0-1] and reshape to [60000,784] (60000 is total image to training)\n",
    "Convert label to one hot vector look like [0,0,1,0,0,0,0,0,0,0] corresponding to number two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25c2d0ab-b1ec-4720-889e-6f83e62978b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape: (60000, 784)\n",
      "Label shape: (60000, 10)\n",
      "Image Value: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
      " 0.49411765 0.53333333 0.68627451 0.10196078 0.65098039 1.\n",
      " 0.96862745 0.49803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      " 0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.19215686\n",
      " 0.93333333 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.98431373 0.36470588 0.32156863\n",
      " 0.32156863 0.21960784 0.15294118 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07058824 0.85882353 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.99215686 0.77647059 0.71372549\n",
      " 0.96862745 0.94509804 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      " 0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05490196 0.00392157 0.60392157 0.99215686 0.35294118\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.54509804 0.99215686 0.74509804 0.00784314 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04313725\n",
      " 0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.1372549  0.94509804\n",
      " 0.88235294 0.62745098 0.42352941 0.00392157 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.31764706 0.94117647 0.99215686\n",
      " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      " 0.58823529 0.10588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0627451  0.36470588 0.98823529 0.99215686 0.73333333\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.97647059 0.99215686 0.97647059 0.25098039 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      " 0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.15294118 0.58039216\n",
      " 0.89803922 0.99215686 0.99215686 0.99215686 0.98039216 0.71372549\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.09411765 0.44705882 0.86666667 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.78823529 0.30588235 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      " 0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.07058824 0.67058824\n",
      " 0.85882353 0.99215686 0.99215686 0.99215686 0.99215686 0.76470588\n",
      " 0.31372549 0.03529412 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.21568627 0.6745098  0.88627451 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 0.95686275 0.52156863 0.04313725 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.53333333 0.99215686\n",
      " 0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "Label shape: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x217411c0280>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "import struct\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def read_idx(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        dims = struct.unpack('>HBB', f.read(4))[2]\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "\n",
    "\n",
    "def load_mnist(image_path, label_path):\n",
    "    images = read_idx(image_path)\n",
    "    labels = read_idx(label_path)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "# Dataset from http://yann.lecun.com/exdb/mnist/\n",
    "train_images, train_labels = load_mnist('./mnist-data/train-images.idx3-ubyte',\n",
    "                                        './mnist-data/train-labels.idx1-ubyte')\n",
    "test_images, test_labels = load_mnist('./mnist-data/t10k-images.idx3-ubyte',\n",
    "                                      './mnist-data/t10k-labels.idx1-ubyte')\n",
    "train_images = np.reshape(train_images, [-1, 784]) / 255\n",
    "test_images = np.reshape(test_images, [-1, 784]) / 255\n",
    "\n",
    "n_values = np.max(train_labels) + 1\n",
    "train_labels_normalize = np.eye(n_values)[train_labels]\n",
    "\n",
    "n_values = np.max(test_labels) + 1\n",
    "test_labels_normalize = np.eye(n_values)[test_labels]\n",
    "print(f'Image Shape: {train_images.shape}')\n",
    "print(f'Label shape: {train_labels_normalize.shape}')\n",
    "print(f'Image Value: {train_images[0]}')\n",
    "print(f'Label shape: {train_labels_normalize[0]}')\n",
    "\n",
    "# show image and label\n",
    "index = 0\n",
    "plt.xlabel('gt = {}'.format(train_labels[index]), color = 'g')\n",
    "plt.imshow(train_images[index].reshape([28,28]), cmap = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fb37ff-ac06-409d-b503-abc9ab92a08c",
   "metadata": {},
   "source": [
    "# Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3940c604-dd1c-4d74-9d33-18e55cbfdaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def he_initialize(shape):\n",
    "    stddev = np.sqrt(2 / shape[0])\n",
    "    return np.random.randn(*shape) * stddev\n",
    "def xavier_initialize(shape):\n",
    "    stddev = np.sqrt(1 / shape[0])\n",
    "    return np.random.randn(*shape) * stddev\n",
    "\n",
    "# Activation sigmoid\n",
    "def sigmoid(arr):\n",
    "    return [1 / (1 + math.exp(-x)) for x in arr]\n",
    "\n",
    "\n",
    "# Sigmoid Derivative Function\n",
    "def sigmoid_derivative(arr):\n",
    "    return [x * (1 - x) for x in arr]\n",
    "\n",
    "# Activation Relu\n",
    "def relu(arr):\n",
    "    return [0 if x < 0 else x for x in arr]\n",
    "\n",
    "# Relu Derivative Function\n",
    "def relu_derivative(arr):\n",
    "    return [1 if x > 0 else 0 for x in arr]\n",
    "\n",
    "def softmax(x):\n",
    "    max_x = max(x)\n",
    "    exp_x = [math.exp(i - max_x) for i in x]\n",
    "    sum_exp_x = sum(exp_x)\n",
    "    return [i / sum_exp_x for i in exp_x]\n",
    "\n",
    "def softmax_derivative(x):\n",
    "    s = softmax(x)\n",
    "    return [s[i] * (1 - s[i]) for i in range(len(x))]\n",
    "\n",
    "\n",
    "# Mean Squared Error\n",
    "def mse(outputs, targets):\n",
    "    return [(o - t) ** 2 for o, t in zip(outputs, targets)]\n",
    "def mse_gradient():\n",
    "    return [2*(p - t) for p,t in zip(y_pred,y_true)]\n",
    "\n",
    "def categorical_crossentropy(y_pred, y_true):\n",
    "    return [-t * math.log(p) for p,t in zip(y_pred,y_true)]\n",
    "\n",
    "def categorical_crossentropy_gradient(y_pred, y_true):\n",
    "    return [p - t for p,t in zip(y_pred,y_true)]\n",
    "\n",
    "def leaky_relu(x, alpha=0.01):\n",
    "    if isinstance(x, (list, tuple, set)):\n",
    "        return [leaky_relu(v, alpha) for v in x]\n",
    "    elif isinstance(x, float):\n",
    "        return x if x >= 0 else alpha * x\n",
    "    else:\n",
    "        raise TypeError(\"Input must be a float or a list/tuple/set of floats.\")\n",
    "\n",
    "def leaky_relu_derivative(x, alpha=0.01):\n",
    "\n",
    "    if isinstance(x, (list, tuple, set)):\n",
    "        return [leaky_relu_derivative(v, alpha) for v in x]\n",
    "    elif isinstance(x, float):\n",
    "        return 1 if x >= 0 else alpha\n",
    "    else:\n",
    "        raise TypeError(\"Input must be a float or a list/tuple/set of floats.\")\n",
    "\n",
    "\n",
    "# Return true to early stop training\n",
    "def early_stopping(model, epoch, loss):\n",
    "    return loss < 0.01\n",
    "\n",
    "# Callback each training epoch\n",
    "def epoch_end_callback(model, epoch, loss):\n",
    "    # save model when loss is decrease\n",
    "    if epoch == 0 or (epoch > 0 and loss < model.loss_history[epoch - 1]):\n",
    "        model.save_model('mnist_model.any_extensions')\n",
    "\n",
    "# Print iterations progress\n",
    "def printProgressBar(iteration, total, prefix='', suffix='', decimals=1, length=100, fill='█', printEnd=\"\\r\"):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end=printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa2e87-7b78-40fa-81eb-876cd45c8327",
   "metadata": {},
   "source": [
    "# Define class Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e3ab2b0-ef30-4ca0-971f-5eac62b2fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "        self.biases = None\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def update_weights(self, learning_rate):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2026e6f-5af7-4288-8bd8-aa2f7eb557fc",
   "metadata": {},
   "source": [
    "# Define class Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40b26b70-af26-45b1-8c4a-ad765a32d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_size, output_size, active_func_name='sigmoid'):\n",
    "        self.inputs = None\n",
    "        self.outputs = None\n",
    "        self.grad_biases = None\n",
    "        self.grad_weights = None\n",
    "        self.grad_inputs = None\n",
    "        self.active_func_name = active_func_name\n",
    "        if active_func_name == 'sigmoid':\n",
    "            self.active_func = sigmoid\n",
    "            self.derivative_func = sigmoid_derivative\n",
    "        elif active_func_name == 'relu':\n",
    "            self.active_func = relu\n",
    "            self.derivative_func = relu_derivative\n",
    "        elif active_func_name == 'leaky_relu':\n",
    "            self.active_func = leaky_relu\n",
    "            self.derivative_func = leaky_relu_derivative\n",
    "        elif active_func_name == 'softmax':\n",
    "            self.active_func = softmax\n",
    "            self.derivative_func = softmax_derivative\n",
    "\n",
    "        # self.weights = [[random.uniform(-1, 1) for _ in range(output_size)] for _ in range(input_size)]\n",
    "        if active_func_name == 'sigmoid':\n",
    "            self.weights = xavier_initialize([input_size, output_size])\n",
    "        else:\n",
    "            self.weights = he_initialize([input_size, output_size])\n",
    "        self.biases = [random.uniform(-1, 1) for _ in range(output_size)]\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []\n",
    "        for neuron_weights, bias in zip(zip(*self.weights), self.biases):\n",
    "            activation = sum(w * i for w, i in zip(neuron_weights, inputs)) + bias\n",
    "            self.outputs.append(activation)\n",
    "        self.outputs = self.active_func(self.outputs)   \n",
    "        return self.outputs\n",
    "\n",
    "    def backward(self, grad_output, lr):\n",
    "        self.grad_inputs = [0] * len(self.inputs)\n",
    "        self.grad_weights = [[0] * len(self.outputs) for _ in range(len(self.inputs))]\n",
    "        self.grad_biases = [0] * len(self.outputs)\n",
    "        derivative_outputs = self.derivative_func(self.outputs)\n",
    "            \n",
    "        for i in range(len(self.inputs)):\n",
    "            for j in range(len(self.outputs)):\n",
    "                derivative_value = derivative_outputs[j]\n",
    "                self.grad_inputs[i] += grad_output[j] * self.weights[i][j] * derivative_value\n",
    "                self.grad_weights[i][j] = grad_output[j] * self.inputs[i] * derivative_value\n",
    "                self.grad_biases[j] += grad_output[j] * derivative_value\n",
    "                \n",
    "                # update weights\n",
    "                self.weights[i][j] -= lr * self.grad_weights[i][j]\n",
    "                if i== 0:\n",
    "                    self.biases[j] -= lr * self.grad_biases[j]\n",
    "        return self.grad_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a87820d-5f35-475d-a946-674c1894840c",
   "metadata": {},
   "source": [
    "# Define class Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01512fee-5306-42d9-8ee5-be5e7ab4cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, loss=None, early_stopping_callback=None, epoch_end_callback=None):\n",
    "        self.outputs = None\n",
    "        self.layers = []\n",
    "        self.loss_history = []\n",
    "        self.early_stopping_callback = early_stopping_callback\n",
    "        self.epoch_end_callback = epoch_end_callback\n",
    "        if loss == 'mse':\n",
    "            self.loss_func = mse\n",
    "            self.loss_func_gradient = mse_gradient\n",
    "        elif loss == 'categorical_crossentropy':\n",
    "            self.loss_func = categorical_crossentropy\n",
    "            self.loss_func_gradient = categorical_crossentropy_gradient\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        for layer in self.layers:\n",
    "            inputs = layer.forward(inputs)\n",
    "        return inputs\n",
    "\n",
    "    def backward(self, targets, lr):\n",
    "        grad_output = self.loss_func_gradient(self.outputs, targets)\n",
    "        for layer in reversed(self.layers):\n",
    "            grad_output = layer.backward(grad_output, lr)\n",
    "\n",
    "    def train(self, inputs, targets, epochs, learning_rate):\n",
    "        total_input = len(inputs)\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            accuracy = 0\n",
    "            i = 1\n",
    "            for input_vector, target_vector in zip(inputs, targets):\n",
    "                self.outputs = self.forward(input_vector)\n",
    "                total_loss += sum(self.loss_func(self.outputs, target_vector))\n",
    "                self.backward(target_vector, learning_rate)\n",
    "                # show progress bar\n",
    "                if i % 100 == 0:\n",
    "                    printProgressBar(i, total_input, prefix=f'{i} / {total_input}:',\n",
    "                                     suffix=f'Complete - Loss: {total_loss / i if i > 0 else total_loss}, Accuracy: {(accuracy*100/i):.2f}%', length=50)\n",
    "                i += 1\n",
    "                \n",
    "                # count accuracy\n",
    "                if np.argmax(self.outputs) == np.argmax(target_vector):\n",
    "                    accuracy += 1\n",
    "            # avg loss\n",
    "            loss = total_loss / len(inputs)\n",
    "            # save loss history\n",
    "            self.loss_history.append(loss)\n",
    "\n",
    "            if epoch % 1 == 0:\n",
    "                print(f'Epoch {epoch}, Loss: {loss}, Accuracy: {(accuracy*100/total_input):.2f}%')\n",
    "\n",
    "            if self.epoch_end_callback is not None:\n",
    "                self.epoch_end_callback(self, epoch, loss)\n",
    "\n",
    "            if self.early_stopping_callback is not None and self.early_stopping_callback(self, epoch, loss):\n",
    "                break\n",
    "        self.save_model('mnist_model.any_extensions')\n",
    "\n",
    "    def summary(self):\n",
    "        total_params = 0\n",
    "        for layer in self.layers:\n",
    "            layer_params = len(layer.weights) * len(layer.weights[0])\n",
    "            total_params += layer_params\n",
    "            print(\n",
    "                f\"{layer.__class__.__name__} ({len(layer.weights)}, {len(layer.weights[0])}) Activation: '{layer.active_func_name}' Params: {layer_params}\")\n",
    "        print(f'Total Params: {total_params}')\n",
    "\n",
    "    def save_model(self, filename):\n",
    "        with open(filename, 'w') as f:\n",
    "            for layer in self.layers:\n",
    "                weights = layer.weights\n",
    "                biases = layer.biases\n",
    "                f.write(f'weights:{weights}\\n')\n",
    "                f.write(f'biases:{biases}\\n')\n",
    "                f.write(f'layer_type:{layer.__class__.__name__}\\n')\n",
    "                f.write(f'active_func:{layer.active_func_name}\\n')\n",
    "            print(f'Saved : {filename}')\n",
    "\n",
    "    def load_model(self, filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            self.layers = []\n",
    "            for i in range(0, len(lines), 4):\n",
    "                weights = eval(lines[i].strip().split(':')[1])\n",
    "                biases = eval(lines[i + 1].strip().split(':')[1])\n",
    "                # layer_class look like Dense, Conv, MaxPool ...\n",
    "                layer_class = eval(lines[i + 2].strip().split(':')[1])\n",
    "                active_func = lines[i + 3].strip().split(':')[1]\n",
    "                # TODO check for other layer type eg: Conv, Maxpool ...\n",
    "                layer = layer_class(input_size=len(weights), output_size=len(weights[0]), active_func_name=active_func)\n",
    "                layer.weights = weights\n",
    "                layer.biases = biases\n",
    "                self.layers.append(layer)\n",
    "            print(f'Loaded {filename}')\n",
    "            self.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df067914-e030-41ba-8fc6-6a3538526953",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2991f2c-e87e-4a01-a3bb-52fae15a2f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense (784, 10) Activation: 'leaky_relu' Params: 7840\n",
      "Dense (10, 10) Activation: 'softmax' Params: 100\n",
      "Total Params: 7940\n"
     ]
    }
   ],
   "source": [
    "inputs = train_images\n",
    "targets = train_labels_normalize\n",
    "model = Model(loss='categorical_crossentropy', early_stopping_callback=early_stopping, epoch_end_callback=epoch_end_callback)\n",
    "model.add(Dense(input_size=784, output_size=10, active_func_name='leaky_relu'))\n",
    "model.add(Dense(input_size=10, output_size=10, active_func_name='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b93bd7-2c16-497f-b45c-e943811a59ff",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11237cec-1b55-4ea9-91f6-fb9e229dc92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 / 1000: |██████████████████████████████████████████████████| 100.0% Complete - Loss: 2.4556631002381284, Accuracy: 4.90%\n",
      "Epoch 0, Loss: 2.4556631002381284, Accuracy: 4.90%\n",
      "Saved : mnist_model.any_extensions\n",
      "1000 / 1000: |██████████████████████████████████████████████████| 100.0% Complete - Loss: 2.3530994462586743, Accuracy: 9.80%\n",
      "Epoch 1, Loss: 2.3530994462586743, Accuracy: 9.80%\n",
      "Saved : mnist_model.any_extensions\n",
      "1000 / 1000: |██████████████████████████████████████████████████| 100.0% Complete - Loss: 2.2867109930003617, Accuracy: 13.20%\n",
      "Epoch 2, Loss: 2.2867109930003617, Accuracy: 13.20%\n",
      "Saved : mnist_model.any_extensions\n",
      "1000 / 1000: |██████████████████████████████████████████████████| 100.0% Complete - Loss: 2.234660364360678, Accuracy: 16.60%\n",
      "Epoch 3, Loss: 2.234660364360678, Accuracy: 16.60%\n",
      "Saved : mnist_model.any_extensions\n",
      "1000 / 1000: |██████████████████████████████████████████████████| 100.0% Complete - Loss: 2.183150003384186, Accuracy: 20.00%\n",
      "Epoch 4, Loss: 2.183150003384186, Accuracy: 20.00%\n",
      "Saved : mnist_model.any_extensions\n",
      "1000 / 1000: |██████████████████████████████████████████████████| 100.0% Complete - Loss: 2.1309764332903445, Accuracy: 23.20%\n",
      "Epoch 5, Loss: 2.1309764332903445, Accuracy: 23.20%\n",
      "Saved : mnist_model.any_extensions\n",
      "1000 / 1000: |██████████████████████████████████████████████████| 100.0% Complete - Loss: 2.0802291029306805, Accuracy: 25.30%\n",
      "Epoch 6, Loss: 2.0802291029306805, Accuracy: 25.30%\n",
      "Saved : mnist_model.any_extensions\n",
      "1000 / 1000: |██████████████████████████████████████████████████| 100.0% Complete - Loss: 2.030721282107222, Accuracy: 28.50%\n",
      "Epoch 7, Loss: 2.030721282107222, Accuracy: 28.50%\n",
      "Saved : mnist_model.any_extensions\n",
      "1000 / 1000: |██████████████████████████████████████████████████| 100.0% Complete - Loss: 1.9830174003856988, Accuracy: 32.40%\n",
      "Epoch 8, Loss: 1.9830174003856988, Accuracy: 32.40%\n",
      "Saved : mnist_model.any_extensions\n",
      "1000 / 1000: |██████████████████████████████████████████████████| 100.0% Complete - Loss: 1.9380494712907606, Accuracy: 36.00%\n",
      "Epoch 9, Loss: 1.9380494712907606, Accuracy: 36.00%\n",
      "Saved : mnist_model.any_extensions\n",
      "Saved : mnist_model.any_extensions\n",
      "Saved : mnist_model.any_extensions\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "model.train(inputs[0:1000], targets[0:1000], epochs, learning_rate)\n",
    "model.save_model('mnist_model.any_extensions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2489c51-d112-48f8-a62c-695ace59f6b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47e5df62-9fa9-4e9f-a7d1-101cb85590a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 / 10000: |██████████████████████████████████████████████████| 100.0% Complete - Acc: 37.6%\n",
      "3757 true / 10000 total\n",
      "Acc: 37.6%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random as rd\n",
    "\n",
    "idx = rd.randint(0, len(inputs))\n",
    "for i in range(idx, idx + 5):\n",
    "    output = model.forward(inputs[i])\n",
    "    pred = output.index(max(output))\n",
    "    gt = targets[i].argmax()\n",
    "    plt.subplot(5, 5, i%5+1)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlabel('pred = {}'.format(pred), color = 'g' if pred == gt else 'r')\n",
    "    plt.imshow(inputs[i].reshape([28,28]), cmap = 'binary')\n",
    "import random as rd\n",
    "acc = 0\n",
    "idx = 0\n",
    "length = 10000\n",
    "for i in range(idx, length):\n",
    "    output = model.forward(inputs[i])\n",
    "    pred = output.index(max(output))\n",
    "    gt = targets[i].argmax()\n",
    "    if gt == pred:\n",
    "        acc +=1\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        percent = (\"{0:.\" + str(1) + \"f}\").format(100 * (acc / (i+1)))\n",
    "        printProgressBar(i+1, length, prefix=f'{i+1} / {length}:',\n",
    "                                     suffix=f'Complete - Acc: {percent}%', length=50)\n",
    "percent = (\"{0:.\" + str(1) + \"f}\").format(100 * (acc / float(length)))\n",
    "print(f'{acc} true / {length} total')\n",
    "print(f'Acc: {percent}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2525844-1c2d-419a-9af0-f7bcbdf0e7fc",
   "metadata": {},
   "source": [
    "# Reload Model after saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96e32c1d-631d-471d-9d03-cfe386335434",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3361\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Input \u001b[0;32mIn [10]\u001b[0m in \u001b[0;35m<cell line: 2>\u001b[0m\n    new_model.load_model('mnist_model.any_extensions')\n",
      "\u001b[1;36m  Input \u001b[1;32mIn [5]\u001b[1;36m in \u001b[1;35mload_model\u001b[1;36m\u001b[0m\n\u001b[1;33m    weights = eval(lines[i].strip().split(':')[1])\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m<string>:1\u001b[1;36m\u001b[0m\n\u001b[1;33m    [[ 0.03663385  0.01552201  0.00457376 ... -0.02646988  0.03959375\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO fix reload model\n",
    "new_model = Model(loss='categorical_crossentropy', early_stopping_callback=early_stopping, epoch_end_callback=epoch_end_callback)\n",
    "new_model.load_model('mnist_model.any_extensions')\n",
    "# learning_rate = 0.0001\n",
    "# new_model.train(inputs[0:60000], targets[0:60000], epochs, learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
